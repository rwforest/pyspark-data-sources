{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Clever API - Fetch All Schools, Teachers, and Students\n",
    "\n",
    "This notebook fetches:\n",
    "1. ALL schools in the district\n",
    "2. ALL teachers for each school\n",
    "3. ALL students for each school\n",
    "4. Flattens nested JSON responses\n",
    "5. Saves everything as CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/10/24 19:02:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark_datasources import rest_api_call, flatten_json_response\n",
    "import ast\n",
    "\n",
    "# Initialize Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CleverAPIFetchAll\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Your Clever API token (Chess4Life Dev Sandbox)\n",
    "CLEVER_TOKEN = \"\"\n",
    "\n",
    "# Create dummy input for GET requests\n",
    "dummy_input = spark.createDataFrame([{\"placeholder\": \"dummy\"}])\n",
    "\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1",
   "metadata": {},
   "source": [
    "## Step 1: Fetch ALL Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fetch_schools",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ALL schools...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yipman/Downloads/github/pyspark-data-sources/.venv/lib/python3.14/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py:161: DeprecationWarning: This process (pid=9919) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fetched 241 schools\n",
      "+------------------------+-------------+\n",
      "|school_id               |school_name  |\n",
      "+------------------------+-------------+\n",
      "|5940d254203e37907e0000f0|Slothgreat   |\n",
      "|5940d254203e37907e0000f1|Vultureroad  |\n",
      "|5940d254203e37907e0000f2|Swoopcharm   |\n",
      "|5940d254203e37907e0000f3|Razorgem     |\n",
      "|5940d254203e37907e0000f4|Bunnyflicker |\n",
      "|5940d254203e37907e0000f5|Spearchestnut|\n",
      "|5940d254203e37907e0000f6|Hoofrift     |\n",
      "|5940d254203e37907e0000f7|Elfneon      |\n",
      "|5940d254203e37907e0000f8|Cowlgiant    |\n",
      "|5940d254203e37907e0000f9|Bunnybloom   |\n",
      "+------------------------+-------------+\n",
      "only showing top 10 rows\n",
      "Total schools: 241\n"
     ]
    }
   ],
   "source": [
    "print(\"Fetching ALL schools...\")\n",
    "\n",
    "# Use rest_api_call - the recommended PySpark Data Source approach\n",
    "schools_response = rest_api_call(\n",
    "    dummy_input,\n",
    "    url=\"https://api.clever.com/v3.0/schools?limit=10000\",\n",
    "    method=\"GET\",\n",
    "    authType=\"Bearer\",\n",
    "    oauthToken=CLEVER_TOKEN,\n",
    "    queryType=\"inline\",\n",
    "    partitions=\"1\"\n",
    ")\n",
    "\n",
    "# Parse the output column to extract school data\n",
    "school_output = schools_response.select(\"output\").first()[\"output\"]\n",
    "school_data = ast.literal_eval(school_output)\n",
    "\n",
    "# Extract schools\n",
    "all_schools = []\n",
    "for school in school_data.get(\"data\", []):\n",
    "    school_info = school.get(\"data\", {})\n",
    "    all_schools.append({\n",
    "        \"school_id\": school_info.get(\"id\"),\n",
    "        \"school_name\": school_info.get(\"name\"),\n",
    "    })\n",
    "\n",
    "print(f\"✓ Fetched {len(all_schools)} schools\")\n",
    "\n",
    "# Convert to DataFrame - this will be our input for teachers and students\n",
    "schools_df = spark.createDataFrame(all_schools)\n",
    "schools_df.show(10, truncate=False)\n",
    "print(f\"Total schools: {schools_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2",
   "metadata": {},
   "source": [
    "## Step 2: Fetch ALL Teachers for ALL Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fetch_teachers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ALL teachers using schools DataFrame...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/24 19:02:11 WARN DataSourceManager: The data source rest replaced a previously registered data source.\n",
      "25/10/24 19:02:31 WARN TaskSetManager: Stage 11 contains a task of very large size (1047 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fetched teachers for all schools!\n",
      "Teachers response has 241 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"Fetching ALL teachers using schools DataFrame...\")\n",
    "\n",
    "# Use schools_df as input - rest_api_call will make one API call per school\n",
    "teachers_response = rest_api_call(\n",
    "    schools_df,\n",
    "    url=\"https://api.clever.com/v3.0/schools/{school_id}/users?role=teacher&limit=10000\",\n",
    "    method=\"GET\",\n",
    "    authType=\"Bearer\",\n",
    "    oauthToken=CLEVER_TOKEN,\n",
    "    queryType=\"inline\"\n",
    ")\n",
    "\n",
    "print(f\"✓ Fetched teachers for all schools!\")\n",
    "print(f\"Teachers response has {teachers_response.count()} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3",
   "metadata": {},
   "source": [
    "## Step 3: Fetch ALL Students for ALL Schools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fetch_students",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ALL students using schools DataFrame...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/24 19:02:31 WARN DataSourceManager: The data source rest replaced a previously registered data source.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fetched students for all schools!\n",
      "Students response has 241 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/24 19:03:01 WARN TaskSetManager: Stage 16 contains a task of very large size (5790 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "print(\"Fetching ALL students using schools DataFrame...\")\n",
    "\n",
    "# Use schools_df as input - rest_api_call will make one API call per school\n",
    "students_response = rest_api_call(\n",
    "    schools_df,\n",
    "    url=\"https://api.clever.com/v3.0/schools/{school_id}/users?role=student&limit=10000\",\n",
    "    method=\"GET\",\n",
    "    authType=\"Bearer\",\n",
    "    oauthToken=CLEVER_TOKEN,\n",
    "    queryType=\"inline\"\n",
    ")\n",
    "\n",
    "print(f\"✓ Fetched students for all schools!\")\n",
    "print(f\"Students response has {students_response.count()} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4",
   "metadata": {},
   "source": [
    "## Step 4: Flatten Nested JSON Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "flatten_teachers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattening teachers data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/24 19:03:02 WARN TaskSetManager: Stage 19 contains a task of very large size (1047 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Flattened 8490 individual teachers\n",
      "Columns: ['created', 'district', 'email', 'id', 'last_modified', 'name_first', 'name_last', 'roles_teacher_credentials_district_username', 'roles_teacher_legacy_id', 'roles_teacher_school', 'roles_teacher_schools', 'roles_teacher_sis_id', 'roles_teacher_state_id', 'roles_teacher_teacher_number', 'roles_teacher_title', 'school_id', 'school_name', 'name_middle']\n",
      "+------------------------+------------------------+----------------------------------------------------------------+------------------------+------------------------+----------+-----------------------------------+-------------------------------------------+------------------------+------------------------+------------------------+--------------------+----------------------+----------------------------+-------------------+------------------------+-----------+-----------+\n",
      "|created                 |district                |email                                                           |id                      |last_modified           |name_first|name_last                          |roles_teacher_credentials_district_username|roles_teacher_legacy_id |roles_teacher_school    |roles_teacher_schools   |roles_teacher_sis_id|roles_teacher_state_id|roles_teacher_teacher_number|roles_teacher_title|school_id               |school_name|name_middle|\n",
      "+------------------------+------------------------+----------------------------------------------------------------+------------------------+------------------------+----------+-----------------------------------+-------------------------------------------+------------------------+------------------------+------------------------+--------------------+----------------------+----------------------------+-------------------+------------------------+-----------+-----------+\n",
      "|2021-03-10T03:18:12.702Z|5940d0b58ec81e0001541ef3|alexander.keihanaikukauakahihuliheekahaunaele.139359@example.com|60482973a24d9900a0a49c55|2021-03-10T03:18:12.702Z|Alexander |Keihanaikukauakahihuliheekahaunaele|                                           |5940d26c480568ae7e003f7e|5940d254203e37907e000100|5940d254203e37907e000100|139359              |                      |139359                      |Teacher            |5940d254203e37907e0000f8|Cowlgiant  |NULL       |\n",
      "|2021-03-10T03:18:12.704Z|5940d0b58ec81e0001541ef3|liam.jinglehimerschmidt.121819@example.com                      |60482973a24d9900a0a49c56|2021-03-10T03:18:12.704Z|Liam      |Jinglehimerschmidt                 |                                           |5940d26a480568ae7e003986|5940d254203e37907e000100|5940d254203e37907e000100|121819              |53628547              |121819                      |Teacher            |5940d254203e37907e0000f8|Cowlgiant  |NULL       |\n",
      "|2021-03-10T03:18:12.705Z|5940d0b58ec81e0001541ef3|noah.jones.124563@example.com                                   |60482973a24d9900a0a49c57|2021-03-10T03:18:12.705Z|Noah      |Jones                              |                                           |5940d26a480568ae7e0039c9|5940d254203e37907e000100|5940d254203e37907e000100|124563              |50567344              |124563                      |                   |5940d254203e37907e0000f8|Cowlgiant  |NULL       |\n",
      "|2021-03-10T03:18:12.707Z|5940d0b58ec81e0001541ef3|kistiñe.jinglehimer'schmidt.124706@example.com                  |60482973a24d9900a0a49c58|2021-03-10T03:18:12.707Z|Kistiñe   |Jinglehimer'schmidt                |                                           |5940d26a480568ae7e0039f8|5940d254203e37907e000100|5940d254203e37907e000100|124706              |51101279              |124706                      |Teacher            |5940d254203e37907e0000f8|Cowlgiant  |NULL       |\n",
      "|2021-03-10T03:18:12.710Z|5940d0b58ec81e0001541ef3|matthew.wilson.125221@example.com                               |60482973a24d9900a0a49c59|2021-03-10T03:18:12.710Z|Matthew   |Wilson                             |                                           |5940d26a480568ae7e003a71|5940d254203e37907e000100|5940d254203e37907e000100|125221              |51645781              |125221                      |                   |5940d254203e37907e0000f8|Cowlgiant  |NULL       |\n",
      "+------------------------+------------------------+----------------------------------------------------------------+------------------------+------------------------+----------+-----------------------------------+-------------------------------------------+------------------------+------------------------+------------------------+--------------------+----------------------+----------------------------+-------------------+------------------------+-----------+-----------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored while finalizing file <_io.BufferedWriter name=5>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yipman/Downloads/github/pyspark-data-sources/.venv/lib/python3.14/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 200, in manager\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "print(\"Flattening teachers data...\")\n",
    "\n",
    "# Use flatten_json_response to extract and flatten the nested \"data\" array\n",
    "# Clever API returns: {\"data\": [{\"data\": {...teacher fields...}}, ...]}\n",
    "# fully_flatten=True recursively flattens ALL nested dicts into columns (default)\n",
    "# This converts name:{first, last, middle} -> name_first, name_last, name_middle\n",
    "teachers_df = flatten_json_response(\n",
    "    teachers_response,\n",
    "    json_path=\"data\",           # Extract the \"data\" array\n",
    "    flatten_nested_key=\"data\",  # Each item has nested \"data\" object to flatten\n",
    "    fully_flatten=True          # Recursively flatten all nested structures\n",
    ")\n",
    "\n",
    "print(f\"✓ Flattened {teachers_df.count()} individual teachers\")\n",
    "print(f\"Columns: {teachers_df.columns}\")\n",
    "teachers_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "flatten_students",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattening students data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/24 19:03:04 WARN TaskSetManager: Stage 24 contains a task of very large size (5790 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/10/24 19:03:20 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/10/24 19:03:20 WARN TaskSetManager: Stage 25 contains a task of very large size (2454 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Flattened 56908 individual students\n",
      "Columns: ['created', 'district', 'email', 'id', 'last_modified', 'name_first', 'name_last', 'name_middle', 'roles_student_credentials_district_username', 'roles_student_dob', 'roles_student_email', 'roles_student_enrollments', 'roles_student_gender', 'roles_student_grade', 'roles_student_graduation_year', 'roles_student_hispanic_ethnicity', 'roles_student_location_address', 'roles_student_location_city', 'roles_student_location_state', 'roles_student_location_zip', 'roles_student_race', 'roles_student_school', 'roles_student_schools', 'roles_student_sis_id', 'roles_student_state_id', 'roles_student_student_number', 'school_id', 'school_name']\n",
      "+------------------------+------------------------+-------------------------------------------+------------------------+------------------------+----------+------------------+------------+-------------------------------------------+-----------------+-------------------------------------------+-------------------------+--------------------+-------------------+-----------------------------+--------------------------------+------------------------------+---------------------------+----------------------------+--------------------------+------------------+------------------------+------------------------+--------------------+----------------------+----------------------------+------------------------+-------------+\n",
      "|created                 |district                |email                                      |id                      |last_modified           |name_first|name_last         |name_middle |roles_student_credentials_district_username|roles_student_dob|roles_student_email                        |roles_student_enrollments|roles_student_gender|roles_student_grade|roles_student_graduation_year|roles_student_hispanic_ethnicity|roles_student_location_address|roles_student_location_city|roles_student_location_state|roles_student_location_zip|roles_student_race|roles_student_school    |roles_student_schools   |roles_student_sis_id|roles_student_state_id|roles_student_student_number|school_id               |school_name  |\n",
      "+------------------------+------------------------+-------------------------------------------+------------------------+------------------------+----------+------------------+------------+-------------------------------------------+-----------------+-------------------------------------------+-------------------------+--------------------+-------------------+-----------------------------+--------------------------------+------------------------------+---------------------------+----------------------------+--------------------------+------------------+------------------------+------------------------+--------------------+----------------------+----------------------------+------------------------+-------------+\n",
      "|2021-03-10T03:17:05.731Z|5940d0b58ec81e0001541ef3|abigail.wilson.322712@example.com          |5940d2d57a70493c1401387b|2021-03-10T03:17:05.731Z|Abigail   |Wilson            |Weaselbrown |                                           |9/23/2003        |abigail.wilson.322712@example.com          |                         |F                   |6                  |                             |                                |                              |                           |                            |                          |                  |5940d254203e37907e0000f0|5940d254203e37907e0000f0|322712              |1049119525            |322712                      |5940d254203e37907e0000f0|Slothgreat   |\n",
      "|2021-03-10T03:16:26.920Z|5940d0b58ec81e0001541ef3|jacob.jinglehimerschmidt.238045@example.com|5940d2ae7a70493c1400ecae|2021-03-10T03:16:26.920Z|Jacob     |Jinglehimerschmidt|Yakquasar   |                                           |8/8/1997         |jacob.jinglehimerschmidt.238045@example.com|                         |M                   |11                 |                             |                                |                              |                           |                            |                          |                  |5940d254203e37907e0000f8|5940d254203e37907e0000f8|238045              |1078243616            |238045                      |5940d254203e37907e0000f4|Bunnyflicker |\n",
      "|2021-03-10T03:16:33.826Z|5940d0b58ec81e0001541ef3|NULL                                       |5940d2b47a70493c1400fa25|2021-03-10T03:16:33.826Z|Chloe     |Martinez          |Cranehate   |                                           |9/22/1997        |NULL                                       |                         |M                   |12                 |                             |                                |                              |                           |                            |                          |                  |5940d254203e37907e0000f8|5940d254203e37907e0000f8|249789              |1039139617            |249789                      |5940d254203e37907e0000f4|Bunnyflicker |\n",
      "|2021-03-10T03:16:45.949Z|5940d0b58ec81e0001541ef3|NULL                                       |5940d2c17a70493c140111b2|2021-03-10T03:16:45.949Z|Alexander |Smith             |Spiritzircon|                                           |2/16/2003        |NULL                                       |                         |M                   |7                  |                             |                                |                              |                           |                            |90474                     |                  |5940d254203e37907e0000fa|5940d254203e37907e0000fa|295777              |1094082716            |295777                      |5940d254203e37907e0000f5|Spearchestnut|\n",
      "|2021-03-10T03:18:10.874Z|5940d0b58ec81e0001541ef3|NULL                                       |5940d30f7a70493c1401b7b7|2021-03-10T03:18:10.874Z|John-Paul |Martinez          |NULL        |                                           |3/15/2005        |NULL                                       |                         |F                   |4                  |                             |                                |                              |                           |                            |                          |                  |5940d254203e37907e0000fa|5940d254203e37907e0000fa|382928              |1082929522            |382928                      |5940d254203e37907e0000f5|Spearchestnut|\n",
      "+------------------------+------------------------+-------------------------------------------+------------------------+------------------------+----------+------------------+------------+-------------------------------------------+-----------------+-------------------------------------------+-------------------------+--------------------+-------------------+-----------------------------+--------------------------------+------------------------------+---------------------------+----------------------------+--------------------------+------------------+------------------------+------------------------+--------------------+----------------------+----------------------------+------------------------+-------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/24 19:03:20 WARN TaskSetManager: Stage 28 contains a task of very large size (2454 KiB). The maximum recommended task size is 1000 KiB.\n",
      "Exception ignored while finalizing file <_io.BufferedWriter name=5>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yipman/Downloads/github/pyspark-data-sources/.venv/lib/python3.14/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 200, in manager\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "print(\"Flattening students data...\")\n",
    "\n",
    "# Use flatten_json_response to extract and flatten the nested \"data\" array\n",
    "# Clever API returns: {\"data\": [{\"data\": {...student fields...}}, ...]}\n",
    "# fully_flatten=True recursively flattens ALL nested dicts into columns (default)\n",
    "# This converts name:{first, last, middle} -> name_first, name_last, name_middle\n",
    "# and roles:{student:{...}} -> roles_student_dob, roles_student_gender, etc.\n",
    "students_df = flatten_json_response(\n",
    "    students_response,\n",
    "    json_path=\"data\",           # Extract the \"data\" array\n",
    "    flatten_nested_key=\"data\",  # Each item has nested \"data\" object to flatten\n",
    "    fully_flatten=True          # Recursively flatten all nested structures\n",
    ")\n",
    "\n",
    "print(f\"✓ Flattened {students_df.count()} individual students\")\n",
    "print(f\"Columns: {students_df.columns}\")\n",
    "students_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5",
   "metadata": {},
   "source": [
    "## Step 5: Save Flattened Data as CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "save_csv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Schools saved to output/schools.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/24 19:03:20 WARN TaskSetManager: Stage 30 contains a task of very large size (2536 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Teachers saved to output/teachers.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/24 19:03:21 WARN TaskSetManager: Stage 31 contains a task of very large size (19539 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Students saved to output/students.csv\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Schools:  241\n",
      "Teachers: 8490\n",
      "Students: 56908\n",
      "\n",
      "All data has been flattened and saved as CSV files.\n",
      "Each CSV file contains one row per school/teacher/student.\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/10/24 19:03:21 WARN TaskSetManager: Stage 38 contains a task of very large size (2454 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    }
   ],
   "source": [
    "# Save Schools\n",
    "schools_output = \"output/schools.csv\"\n",
    "schools_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(schools_output)\n",
    "print(f\"✓ Schools saved to {schools_output}\")\n",
    "\n",
    "# Save Teachers (flattened - one row per teacher)\n",
    "teachers_output = \"output/teachers.csv\"\n",
    "teachers_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(teachers_output)\n",
    "print(f\"✓ Teachers saved to {teachers_output}\")\n",
    "\n",
    "# Save Students (flattened - one row per student)\n",
    "students_output = \"output/students.csv\"\n",
    "students_df.coalesce(1).write.mode(\"overwrite\").option(\"header\", \"true\").csv(students_output)\n",
    "print(f\"✓ Students saved to {students_output}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Schools:  {schools_df.count()}\")\n",
    "print(f\"Teachers: {teachers_df.count()}\")\n",
    "print(f\"Students: {students_df.count()}\")\n",
    "print(\"\\nAll data has been flattened and saved as CSV files.\")\n",
    "print(\"Each CSV file contains one row per school/teacher/student.\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
